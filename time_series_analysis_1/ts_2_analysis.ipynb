{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Forecasting with Bayesian Inference\n",
    "\n",
    "This notebook demonstrates the use of Bayesian inference for sales forecasting using various probabilistic programming techniques. We will use the `numpyro` library to define and fit our models, and `plotnine` for visualization.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Bayesian inference allows us to incorporate prior knowledge and quantify uncertainty in our predictions. This notebook will guide you through the process of building a Bayesian model for sales forecasting, fitting the model using Markov Chain Monte Carlo (MCMC) and Stochastic Variational Inference (SVI), and visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries And Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set XLA_FLAGS before JAX is imported\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import ggplot, aes, geom_point, geom_line, labs, theme_minimal, theme_bw, scale_x_continuous, scale_x_discrete, scale_x_datetime\n",
    "import patsy\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "#from numpyro.infer import SVI, Trace_ELBO, Predictive\n",
    "from numpyro.infer import MCMC, NUTS, MCMC, NUTS #, SVI, Trace_ELBO\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model\n",
    "\n",
    "In this section, we define the Bayesian model used for sales forecasting. The model incorporates various components such as random walk for the latent state, day-of-the-week effects, day-of-the-year effects, and price elasticity. The model is implemented using the `numpyro` library, which allows for efficient and scalable Bayesian inference.\n",
    "\n",
    "### 1.1 Auxiliary Functions\n",
    "\n",
    "These auxiliary functions are essential for data preprocessing and transformation:\n",
    "\n",
    "- `periodic_rbf`: Computes a periodic Gaussian radial basis function (RBF).\n",
    "- `compute_doy_basis`: Computes 12 periodic Gaussian basis functions for seasonal effects.\n",
    "- `read_data`: Reads and preprocesses the sales data from a CSV file.\n",
    "- `init_values`: Initializes values for the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a periodic Gaussian radial basis function (RBF)\n",
    "def periodic_rbf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "    Computes a periodic Gaussian radial basis function (RBF).\n",
    "    \n",
    "    Args:\n",
    "        x: Scaled day-of-year values (range [0,1]).\n",
    "        mu: Center of the Gaussian basis function.\n",
    "        sigma: Controls the spread of the Gaussian.\n",
    "    \n",
    "    Returns:\n",
    "        RBF values preserving periodicity.\n",
    "    \"\"\"\n",
    "    # compute cyclic distance to mu\n",
    "    periodic_distance = jnp.minimum(jnp.abs(x - mu), 1 - jnp.abs(x - mu))\n",
    "    # compute RBF value\n",
    "    return jnp.exp(- (periodic_distance ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "def compute_doy_basis(yday_fraction, sigma = 30/365.25, n_centers = 12):\n",
    "    \"\"\"\n",
    "    Computes 12 periodic Gaussian basis functions for seasonal effects.\n",
    "    \n",
    "    Args:\n",
    "        yday_fraction: Normalized day of the year (range [0,1]).\n",
    "        yday_factor: Scaling factor for basis function width.\n",
    "    \n",
    "    Returns:\n",
    "        A JAX array with 12 columns representing the 12 monthly basis functions.\n",
    "    \"\"\"\n",
    "    # Define centers of Gaussian basis functions\n",
    "    month_centers = jnp.linspace( 1/(2*n_centers), 1-1/(2*n_centers), n_centers)\n",
    "    \n",
    "    # Generate an array of shape (length of input, 12) with the RBF values\n",
    "    doy_basis = jnp.stack([periodic_rbf(yday_fraction, mu, sigma) for mu in month_centers], axis=-1)\n",
    "\n",
    "    # Subtract each row's mean to enforce sum-to-zero constraint\n",
    "    doy_basis_centered = doy_basis - jnp.mean(doy_basis, axis=-1, keepdims=True)\n",
    "    \n",
    "    return doy_basis_centered\n",
    "\n",
    "def read_data(fname):\n",
    "    \"\"\"\n",
    "    Reads and preprocesses the sales data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        fname: The filename of the CSV file containing the sales data.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary with the following keys:\n",
    "            - sales: An array of sales data.\n",
    "            - log_price: An array of log-transformed prices.\n",
    "            - wday: An array of day-of-the-week values.\n",
    "            - yday_fraction: An array of normalized day-of-the-year values.\n",
    "    \"\"\"\n",
    "    # Read the CSV file using polars\n",
    "    df = pl.read_csv(fname)\n",
    "    \n",
    "    # Convert the 'date' column to date type\n",
    "    df = df.with_columns(pl.col(\"date\").str.to_date())\n",
    "\n",
    "    # Extract sales, and log price data as a numpy arrays\n",
    "    sales = df[\"sales\"].to_numpy()\n",
    "    log_price = df[\"log_price\"].to_numpy()\n",
    "    \n",
    "    # Extract day-of-the-week values\n",
    "    wday = df[\"date\"].dt.weekday().to_numpy()\n",
    "    \n",
    "    # Extract day-of-the-year values\n",
    "    yday = df[\"date\"].dt.ordinal_day().to_numpy()\n",
    "    \n",
    "    # Determine if the year is a leap year\n",
    "    is_leap_year = df[\"date\"].dt.is_leap_year().to_numpy()\n",
    "    \n",
    "    # Normalize day-of-the-year values\n",
    "    yday_fraction = yday / (365 + is_leap_year)\n",
    "    \n",
    "    # Return the preprocessed data as a dictionary\n",
    "    return {\n",
    "        \"sales\": sales,\n",
    "        \"log_price\": log_price,\n",
    "        \"wday\": wday,\n",
    "        \"yday_fraction\": yday_fraction\n",
    "    }\n",
    "\n",
    "#def init_values(sales: jnp.array, log_price_centered: jnp.array, wday, yday_fraction: jnp.array, downsampling_factor = 1):\n",
    "#    \"\"\"\n",
    "#    \"\"\"\n",
    "#    # to-do: implement downsampling_factor\n",
    "#    log_state_est = jnp.log(sales)\n",
    "#    log_state_mean_est = jnp.mean(log_state_est)\n",
    "#    log_state_delta_est = jnp.diff(log_state_est)\n",
    "#    log_state_delta_sd_est = jnp.std(log_state_delta_est)\n",
    "#\n",
    "#    return {\n",
    "#        \"log_sigma\": jnp.log( log_state_delta_sd_est ),\n",
    "#        \"log_state_mean\": log_state_mean_est,\n",
    "#        \"log_state_delta\": log_state_delta_est,\n",
    "#        \"wday_coefficients\": jnp.array([0.0]*6),\n",
    "#        \"yday_coefficients\": jnp.array([0.0]*12),\n",
    "#        \"log_elasticity\": jnp.array([0.0])\n",
    "#    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Model\n",
    "\n",
    "#### 1.2.1 Key Features\n",
    "\n",
    "- Sales are modeled using a **stochastic Poisson process**, where the expected rate $\\lambda_t$ evolves over time.\n",
    "- The **latent sales rate** follows a random walk, allowing it to drift nonstationarily.\n",
    "- **Seasonal components** (day-of-the-week and annual patterns) adjust for structured demand variations.\n",
    "- **Price elasticity** is explicitly modeled, ensuring sensitivity to pricing dynamics.\n",
    "- The model is implemented in numpyro, enabling scalable Bayesian inference.\n",
    "\n",
    "\n",
    "#### 1.2.1 Model Overview\n",
    "\n",
    "We model the sales time series as a **stochastic process** where the underlying rate of sales evolves over time. This evolution follows a **random walk structure**, but with systematic adjustments for covariates such as price, day-of-the-week effects, and day-of-the-year effects. The rate of sales $\\lambda_t$ on day $t$ is a function of captures *(i)* systematic covariate effects ($z_t$), *(ii)*\n",
    "a global baseline ($\\mu_\\tau$), and *(iii)* the latent dynamic component ($\\tau_t$).\n",
    "\n",
    "$$\n",
    "log~\\lambda_t = z_t + \\mu_\\tau + \\tau_t\n",
    "$$\n",
    "\n",
    "##### 1.2.1.1 Latent States Dynamics\n",
    "\n",
    "The baseline sales level $\\tau_t$ follows a **random walk**. Because all contrast matrices for structured effects are centered, $\\mu_\\tau + \\tau_t$ can be interpreted as the average latent sales rate on $\\tau_t$. \n",
    "\n",
    "$$\n",
    "\\tau_t = \\tau_{t-1} + \\delta_t, \\quad \\delta_t \\sim \\mathcal{N}(0, \\sigma_\\tau)\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\mu_\\tau \\sim \\text{Exponential}(1), \\quad \\sigma_\\tau \\sim \\mathcal{N}(1)\n",
    "$$\n",
    "\n",
    "\n",
    "##### 1.2.1.2 Structured Effects\n",
    "\n",
    "We further accounted for systematic effects of *(i)* day of the week, *(ii)* day of the year, and *(iii)* price.\n",
    "\n",
    "- For day of the week effects, we used a contrast matrix $\\mathbf{C}_{\\text{wday}}$ with sliding differences.\n",
    "- For day of the year effects, we used a matrix of Gaussian radial basis functions $\\mathbf{B}_{\\text{yday}}$.\n",
    "- Price elasticity is modelled using a centered log price \n",
    "\n",
    "Similarly, the day-of-the-year effects are modeled using a seasonality basis matrix $\\mathbf{B}_{\\text{yday}}$, which represents periodic seasonal patterns using Gaussian radial basis functions (RBFs).\n",
    "\n",
    "\n",
    "- **Day-of-the-week effects**:\n",
    "\n",
    "$$\n",
    "  zw_t = \\mathbf{C}_{\\text{wday}} \\cdot \\beta_{\\text{wday}}, \\quad \\beta_{\\text{wday}} \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "- **Day-of-the-year effects**:\n",
    "\n",
    "$$\n",
    "  zy_t = \\mathbf{B}_{\\text{yday}} \\cdot \\beta_{\\text{yday}}, \\quad \\beta_{\\text{yday}} \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "- **Price elasticity**:\n",
    "\n",
    "$$\n",
    "  ze_t = \\text{log\\_price\\_centered} \\cdot e, \\quad \\log(-e) \\sim \\mathcal{N^{+}}(0, 1)\n",
    "$$\n",
    "\n",
    "- **Sum of structural effects**:\n",
    "\n",
    "$$\n",
    "  z_t = zw_t + zy_t + ze_t\n",
    "$$\n",
    "\n",
    "\n",
    "##### 1.2.1.3 Emissions Model\n",
    "\n",
    "Observed sales are assumed to follow a **Poisson distribution**, ensuring discrete, non-negative observations:\n",
    "\n",
    "$$\n",
    "S_t \\sim \\text{Poisson}(\\lambda_t)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_local_level_poisson(sales: jnp.array, log_price_centered: jnp.array, wday, yday_fraction: jnp.array, \n",
    "                              contrasts_sdif_t: jnp.array, contrasts_wday: jnp.array, contrasts_yday: jnp.array, \n",
    "                              downsampling_factor = 1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    n_obs = len(sales)\n",
    "    n_states = contrasts_sdif_t.shape[0]\n",
    " \n",
    "    def sample_random_walk(contrasts_sdif_t, n_states):\n",
    "        log_sigma = numpyro.sample(\"log_sigma\", dist.Gumbel(0, 1))\n",
    "        sigma = numpyro.deterministic(\"sigma\", jnp.exp(log_sigma))\n",
    "        log_state_mean = numpyro.sample(\"log_state_mean\", dist.Normal(0, 5))\n",
    "        log_state_delta = numpyro.sample( \"log_state_delta\", dist.Normal(0, 1), sample_shape=(n_states-1,))\n",
    "        log_state_base = numpyro.deterministic(\"log_state_base\", jnp.dot(contrasts_sdif_t, log_state_delta) * sigma + log_state_mean )\n",
    "        return log_state_base\n",
    "\n",
    "    def sample_downsampled_random_walk(contrasts_sdif_t, n_obs, n_states):\n",
    "        log_state_base_downsampled = sample_random_walk(contrasts_sdif_t, n_states)\n",
    "        \n",
    "        idx_n_weight = jnp.array(range(0, n_obs))/downsampling_factor\n",
    "        idx_1 = jnp.array( jnp.floor(idx_n_weight), dtype=int)\n",
    "        idx_2 = jnp.array( jnp.ceil(idx_n_weight), dtype=int)\n",
    "        weight_2 = idx_n_weight - idx_1\n",
    "\n",
    "        state_before = log_state_base_downsampled[idx_1]\n",
    "        state_after = log_state_base_downsampled[idx_2]\n",
    "        return (1-weight_2)*state_before + weight_2*state_after\n",
    "        \n",
    "    def sample_wday_effect(contrasts_wday, wday):\n",
    "        # Prior for day-of-the-week effects (6 coefficients)\n",
    "        wday_coefficients = numpyro.sample(\"wday_coefficients\", dist.Normal(0, 1), sample_shape=(6,))\n",
    "\n",
    "        # Compute wday effect per observation (sum-to-zero constraint applied via contrasts)\n",
    "        wday_effects = jnp.dot(contrasts_wday, wday_coefficients)\n",
    "        return jnp.array([wday_effects[d - 1] for d in wday]) # to-do: just use an index vector instead of a loop\n",
    "\n",
    "    def sample_yday_effect(contrasts_yday, yday_fraction):\n",
    "        \n",
    "        # Compute yday effect per observation (sum-to-zero constraint applied via contrasts)\n",
    "        yday_rbf_width = numpyro.sample(\"yday_rbf_width\", dist.Exponential(10))\n",
    "        contrasts_yday = compute_doy_basis(yday_fraction, sigma = yday_rbf_width, n_centers = 12) # sigma = 30/365.25 # sigma = yday_rbf_width\n",
    "\n",
    "        # Prior for yearly seasonality effects (12 coefficients)\n",
    "        yday_coefficients = numpyro.sample(\"yday_coefficients\", dist.Normal(0, 1), sample_shape=(12,))\n",
    "\n",
    "        return jnp.dot(contrasts_yday, yday_coefficients)\n",
    "\n",
    "    def sample_price_effect(log_price_centered):\n",
    "        # Prior for price elasticity\n",
    "        log_elasticity = numpyro.sample( \"log_elasticity\", dist.Normal(0, 2) ) # dist.TruncatedNormal(-1, 2, high = 0)\n",
    "        elasticity = numpyro.deterministic(\"elasticity\", -1 * log_elasticity)\n",
    "        return log_price_centered * elasticity\n",
    "\n",
    "\n",
    "    # Sample random walk    \n",
    "    if n_obs == n_states:\n",
    "        log_state_base = sample_random_walk(contrasts_sdif_t, n_states)\n",
    "    else:\n",
    "        log_state_base = sample_downsampled_random_walk(contrasts_sdif_t, n_obs, n_states)\n",
    "\n",
    "    # Sample day-of-the-week effects\n",
    "    wday_effect = sample_wday_effect(contrasts_wday, wday)\n",
    "\n",
    "    # Sample day-of-the-year effects\n",
    "    yday_effect = sample_yday_effect(contrasts_yday, yday_fraction)\n",
    "\n",
    "    # Sample elasticity effect\n",
    "    price_effect = sample_price_effect(log_price_centered)\n",
    "\n",
    "    # Compute state\n",
    "    state = numpyro.deterministic(\"state\", jnp.exp(log_state_base  + yday_effect + wday_effect)) # + price_effect\n",
    "\n",
    "    # Compute log-likelihood for poisson emissions\n",
    "    numpyro.sample(\"sales\", dist.Poisson(rate=state), obs=sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Model Fitting Logic\n",
    "\n",
    "- Functions to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_arguments(sales: jnp.array, log_price: jnp.array, wday, yday_fraction: jnp.array, downsampling_factor = 1):\n",
    "    \"\"\" \n",
    "    \"\"\"    \n",
    "    n_obs = len(sales)\n",
    "    if downsampling_factor == 1:\n",
    "        n_states = n_obs\n",
    "    else:\n",
    "        n_states = int( np.floor(n_obs/downsampling_factor) + 1 ) \n",
    "    \n",
    "    # Define contrast matrix for random walk (T coefficients, sum-to-zero constraint)\n",
    "    contrasts_sdif_t = patsy.contrasts.Diff().code_without_intercept(range(0, n_states)).matrix\n",
    "\n",
    "    # Define contrast matrix for day-of-the-week effects (6 coefficients, sum-to-zero constraint)\n",
    "    contrasts_wday = patsy.contrasts.Diff().code_without_intercept(range(0,7)).matrix  # 7 days â†’ 6 contrasts\n",
    "\n",
    "    # Compute yday effect per observation (sum-to-zero constraint applied via contrasts)\n",
    "    contrasts_yday = compute_doy_basis(yday_fraction, sigma = 30/365.25, n_centers = 12)\n",
    "\n",
    "    # Compute centered log price differences\n",
    "    log_price_centered = log_price - jnp.mean(log_price)\n",
    "\n",
    "    # Set up the model parameters\n",
    "    model_arguments = {'sales': sales, 'log_price_centered': log_price_centered, 'wday': wday, 'yday_fraction': yday_fraction,\n",
    "                       'downsampling_factor': downsampling_factor,\n",
    "                       'contrasts_sdif_t': contrasts_sdif_t, 'contrasts_wday': contrasts_wday, 'contrasts_yday': contrasts_yday}\n",
    "    \n",
    "    # # Prepare init values for parameters \n",
    "    # init_params = init_values(sales, log_price_centered, wday, yday_fraction)\n",
    "\n",
    "    #return init_params, model_arguments\n",
    "    return model_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nuts(sales: jnp.array, log_price: jnp.array, wday, yday_fraction: jnp.array, downsampling_factor = 1, n_chains = 1, num_warmup=1_000, num_samples=1_000):\n",
    "    \"\"\" Runs NUTS MCMC inference on the model \n",
    "    \"\"\"\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    \n",
    "    n_obs = len(sales)\n",
    "    \n",
    "    # Prepare model arguments\n",
    "    model_arguments = prepare_model_arguments(sales = sales, log_price = log_price, wday = wday, yday_fraction = yday_fraction, downsampling_factor = downsampling_factor)\n",
    "\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "    numpyro.set_host_device_count(n_chains)\n",
    "\n",
    "    reparam_model = model_local_level_poisson\n",
    "    kernel = NUTS(reparam_model, step_size=0.01, max_tree_depth=8)\n",
    "    mcmc = MCMC(kernel, num_warmup=num_warmup, num_samples=num_samples, num_chains=n_chains)\n",
    "    mcmc.run( rng_key_, **model_arguments) #, init_params = init_params\n",
    "\n",
    "    return mcmc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(\"sales_synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f204642f904387b39c9de79c31e4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b572982f524082a9dc6eb6cc4975f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06845d3aceab431bb60846522523ef95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5260fd2ee1634bc2bb8123be95d31f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_fit = run_nuts(data['sales'], data['log_price'], data['wday'], data['yday_fraction'], downsampling_factor = 7, n_chains = 4, num_warmup=1_000, num_samples=1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elasticity</th>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.349</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.017</td>\n",
       "      <td>27.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yday_rbf_width</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "sigma           0.065  0.006   0.053    0.077      0.001    0.000      23.0   \n",
       "elasticity     -0.114  0.349  -0.761    0.526      0.067    0.017      27.0   \n",
       "yday_rbf_width  0.472  0.292   0.160    0.971      0.097    0.020       8.0   \n",
       "\n",
       "                ess_tail  r_hat  \n",
       "sigma              124.0   1.13  \n",
       "elasticity         113.0   1.11  \n",
       "yday_rbf_width      42.0   1.48  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = az.summary(m_fit)\n",
    "summary.loc[['sigma', 'elasticity', 'yday_rbf_width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame({ 'date': df[\"date\"].to_numpy(), 'sales': df[\"sales\"].to_numpy(), 'state': m['state'] })\n",
    "ggplot(x, aes(x='date', y='sales')) + geom_point() + geom_line(aes(y='state'), color = \"red\") + theme_bw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
